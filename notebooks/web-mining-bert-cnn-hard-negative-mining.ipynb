{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14170330,"sourceType":"datasetVersion","datasetId":8974720}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Uninstall existing versions to clear conflicts\n!pip uninstall -y protobuf tensorboard\n\n# 2. Install a stable, compatible version of protobuf\n!pip install -q protobuf==3.20.3\n\n# 3. Reinstall tensorboard\n!pip install -q tensorboard","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:04:29.019744Z","iopub.execute_input":"2025-12-27T06:04:29.020428Z","iopub.status.idle":"2025-12-27T06:04:39.266428Z","shell.execute_reply.started":"2025-12-27T06:04:29.020397Z","shell.execute_reply":"2025-12-27T06:04:39.265718Z"}},"outputs":[{"name":"stdout","text":"Found existing installation: protobuf 6.33.0\nUninstalling protobuf-6.33.0:\n  Successfully uninstalled protobuf-6.33.0\nFound existing installation: tensorboard 2.18.0\nUninstalling tensorboard-2.18.0:\n  Successfully uninstalled tensorboard-2.18.0\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ntensorflow 2.18.0 requires tensorboard<2.19,>=2.18, which is not installed.\nopentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\na2a-sdk 0.3.10 requires protobuf>=5.29.5, but you have protobuf 3.20.3 which is incompatible.\nray 2.51.1 requires click!=8.3.0,>=7.0, but you have click 8.3.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\ntensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.3 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\ngrpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.18.0 requires tensorboard<2.19,>=2.18, but you have tensorboard 2.20.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport nltk\n\nimport re\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.tensorboard import SummaryWriter  # <--- NEW IMPORT\nfrom tqdm import tqdm\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom transformers import BertModel, BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score, recall_score\nfrom nltk.corpus import wordnet\n\nimport matplotlib.pyplot as plt\ntry:\n    nltk.download('stopwords')\n    from nltk.corpus import stopwords\n    stop_words = set(stopwords.words('english'))\nexcept:\n    from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n    stop_words = set(ENGLISH_STOP_WORDS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:04:39.267851Z","iopub.execute_input":"2025-12-27T06:04:39.268095Z","iopub.status.idle":"2025-12-27T06:05:05.766181Z","shell.execute_reply.started":"2025-12-27T06:04:39.268070Z","shell.execute_reply":"2025-12-27T06:05:05.765428Z"}},"outputs":[{"name":"stderr","text":"2025-12-27 06:04:46.195774: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766815486.387837      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766815486.441731      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Hyperparameters\nMAX_LEN = 256      # Max length of tweets (BERT max is 512, but tweets are short)\nBATCH_SIZE = 16    # 16 or 32 is standard for BERT\nEPOCHS = 2         # BERT fine-tunes quickly (2-4 epochs is usually enough)\nRETRAIN_EPOCHS = 4\nLEARNING_RATE = 1e-5\nRETRAIN_LEARNING_RATE = 5e-6\nUSE_BALANCED = False\nlambdaa = 1.2\nNUM_AUGMENTATIONS_PER_TEXT = 4\nMIN_REPLACEMENT = 4\n# --- 3. Data Loading & Minimal Cleaning ---\nwriter = SummaryWriter(f'runs/BERT_{EPOCHS}_epochs_{LEARNING_RATE}_lr_BALANCED' if USE_BALANCED else f'BERT_NEGATIVE_MINING_{EPOCHS}_epochs_{RETRAIN_EPOCHS}_retrain_epochs_{LEARNING_RATE}_lr')\n\ndef clean_text_bert(text):\n    # Minimal cleaning for BERT. It needs context, so we keep stopwords.\n    text = str(text).lower()\n    text = re.sub(r'rt\\s', '', text)               # Remove RT\n    text = re.sub(r'@\\w+', '', text)               # Remove mentions\n    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text) # Remove URLs\n    text = re.sub(r'&#[0-9]+;', '', text)          # Remove HTML\n    # We KEEP punctuation because BERT uses it for context/structure\n    return text.strip()\n\n# Load Data\ndf = pd.read_csv('/kaggle/input/sentiment-analysis-twitter-hate-speech/train.csv')\ndf_test = pd.read_csv('/kaggle/input/sentiment-analysis-twitter-hate-speech/test.csv')\ndf['clean_text'] = df['tweet'].apply(clean_text_bert)\ndf_test['clean_text'] = df_test['tweet'].apply(clean_text_bert)\n# Split Data\nX_train, X_val, y_train, y_val = train_test_split(\n    df['clean_text'], df['class'], test_size=0.2, random_state=42\n)\n\ndf_balanced_data = pd.read_csv('/kaggle/input/sentiment-analysis-twitter-hate-speech/balanced_data.csv')\nX_train_balanced, X_val_balanced, y_train_balanced, y_val_balanced = train_test_split(\n    df_balanced_data['clean_text'], df_balanced_data['class'], test_size=0.2, random_state=42\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:36:16.319676Z","iopub.execute_input":"2025-12-27T06:36:16.320782Z","iopub.status.idle":"2025-12-27T06:36:16.612920Z","shell.execute_reply.started":"2025-12-27T06:36:16.320755Z","shell.execute_reply":"2025-12-27T06:36:16.611955Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# --- 1. Initialize Tokenizer ---z\n# \ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# --- 2. Custom Dataset Class ---\nclass TwoHeadDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_len):\n        # Reset index to avoid errors if dataframe was shuffled/split\n        self.texts = texts.reset_index(drop=True)\n        self.labels = labels.reset_index(drop=True)\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        text = str(self.texts[item])\n        label = self.labels[item]\n\n        # Encoding: This handles Tokenization, Padding, and Truncation\n        encoding = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,    # Add [CLS] and [SEP]\n            max_length=self.max_len,\n            return_token_type_ids=False,\n            padding='max_length',       # Pad to max_len\n            truncation=True,            # Truncate if too long\n            return_attention_mask=True,\n            return_tensors='pt',        # Return PyTorch tensors\n        )\n\n        return {\n            'text': text,\n            # Flatten because DataLoader adds the batch dimension later\n            'input_ids': encoding['input_ids'].flatten(),\n            'attention_mask': encoding['attention_mask'].flatten(),\n            # We pass the raw label (0, 1, or 2). \n            # The train_fn logic will handle splitting this into binary targets.\n            'labels': torch.tensor(label, dtype=torch.long)\n        }\n\n# --- 3. Create DataLoaders ---\n\n# Create Dataset objects\nif not USE_BALANCED:\n    train_dataset = TwoHeadDataset(\n        texts=X_train, \n        labels=y_train, \n        tokenizer=tokenizer, \n        max_len=MAX_LEN\n    )\n    \n    val_dataset = TwoHeadDataset(\n        texts=X_val, \n        labels=y_val, \n        tokenizer=tokenizer, \n        max_len=MAX_LEN\n    )\nelse:\n    train_dataset = TwoHeadDataset(\n        texts=X_train_balanced, \n        labels=y_train_balanced, \n        tokenizer=tokenizer, \n        max_len=MAX_LEN\n    )\n    \n    val_dataset = TwoHeadDataset(\n        texts=X_val_balanced, \n        labels=y_val_balanced, \n        tokenizer=tokenizer, \n        max_len=MAX_LEN\n    )\ntest_dataset = TwoHeadDataset(\n    texts=df_test['clean_text'],\n    labels=df_test['class'],\n    tokenizer=tokenizer,\n    max_len=MAX_LEN\n)\n# Create DataLoaders\n# shuffle=True for training to break correlations\ntrain_loader = DataLoader(\n    train_dataset, \n    batch_size=BATCH_SIZE, \n    shuffle=True,\n    num_workers=2 # Optional: speeds up data loading\n)\n\n# shuffle=False for validation so results are reproducible\nval_loader = DataLoader(\n    val_dataset, \n    batch_size=BATCH_SIZE, \n    shuffle=False,\n    num_workers=2 \n)\n\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=2\n)\n\nprint(f\"Data Loaded: {len(train_dataset)} training samples, {len(val_dataset)} validation samples.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:36:18.165890Z","iopub.execute_input":"2025-12-27T06:36:18.166318Z","iopub.status.idle":"2025-12-27T06:36:18.993987Z","shell.execute_reply.started":"2025-12-27T06:36:18.166290Z","shell.execute_reply":"2025-12-27T06:36:18.993278Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e13a19c60d44544aafde850bbbecc78"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"612c522a692a4466a9c52d9f9fd7f2cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5808029a8fe8476c9e40a845f3427a19"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f0cbb556d884c7884b3ab895c0b04ae"}},"metadata":{}},{"name":"stdout","text":"Data Loaded: 15860 training samples, 3966 validation samples.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"class BertTwoHeadHier(nn.Module):\n    \"\"\"\n    Hierarchical 3-class via two binary heads:\n      A: toxic?   (0=Neither, 1=Toxic)\n      B: hate?    (0=Offensive, 1=Hate)  computed/trained only on toxic samples\n    \"\"\"\n    def __init__(self, bert_name=\"bert-base-uncased\", dropout=0.1):\n        super().__init__()\n        self.bert = BertModel.from_pretrained(bert_name)\n        hidden = self.bert.config.hidden_size\n        self.drop = nn.Dropout(dropout)\n        self.head_toxic = nn.Linear(hidden, 1)  # logitA\n        self.head_hate  = nn.Linear(hidden, 1)  # logitB\n\n    def forward(self, input_ids, attention_mask=None, token_type_ids=None):\n        out = self.bert(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n            return_dict=True\n        )\n        cls = out.last_hidden_state[:, 0, :]  # [B, H] CLS token\n        cls = self.drop(cls)\n        logitA = self.head_toxic(cls).squeeze(-1)  # [B]\n        logitB = self.head_hate(cls).squeeze(-1)   # [B]\n        return logitA, logitB\n\nclass BertCNN(nn.Module):\n    def __init__(self, n_classes, dropout=0.3):\n        super(BertCNN, self).__init__()\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n        \n        # CNN Hyperparameters\n        embedding_dim = self.bert.config.hidden_size # 768 for bert-base\n        n_filters = 100\n        filter_sizes = [2, 3, 4] # Look at 2-grams, 3-grams, 4-grams\n        \n        # Convolutional Layers\n        # We create a ModuleList of Conv1d layers for different window sizes\n        self.convs = nn.ModuleList([\n            nn.Conv1d(in_channels=embedding_dim, out_channels=n_filters, kernel_size=fs)\n            for fs in filter_sizes\n        ])\n        \n        # Fully Connected Layer\n        self.fc = nn.Linear(len(filter_sizes) * n_filters, n_classes)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, input_ids, attention_mask):\n        # BERT Output\n        # We need the 'last_hidden_state' which has shape [batch_size, seq_len, hidden_dim]\n        output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n        last_hidden_state = output.last_hidden_state\n        \n        # Permute for CNN: [batch, hidden_dim, seq_len]\n        # Conv1d expects channels (hidden_dim) as the second dimension\n        embedded = last_hidden_state.permute(0, 2, 1)\n        \n        # Apply CNN & Max Pooling\n        # For each filter size: Conv1d -> ReLU -> MaxPool1d\n        conved = [F.relu(conv(embedded)) for conv in self.convs]\n        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n        \n        # Concatenate pooled features\n        # Shape: [batch, n_filters * len(filter_sizes)]\n        cat = self.dropout(torch.cat(pooled, dim=1))\n        \n        # Final Classification\n        return self.fc(cat)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:36:20.702714Z","iopub.execute_input":"2025-12-27T06:36:20.703527Z","iopub.status.idle":"2025-12-27T06:36:20.712568Z","shell.execute_reply.started":"2025-12-27T06:36:20.703499Z","shell.execute_reply":"2025-12-27T06:36:20.711837Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=None, gamma=2, reduction='mean'):\n        \"\"\"\n        Args:\n            alpha (float, list, or torch.Tensor): \n                - If float: Applies the same weight to all classes.\n                - If list/Tensor: Weights for each class (e.g., [1.0, 0.5, 0.1]).\n                  Must match the number of classes.\n            gamma (float): Focusing parameter (default 2).\n            reduction (str): 'mean', 'sum', or 'none'.\n        \"\"\"\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.reduction = reduction\n        \n        # Handle alpha\n        if isinstance(alpha, (list, tuple, np.ndarray)):\n            self.alpha = torch.tensor(alpha).float()\n        else:\n            self.alpha = alpha\n\n    def forward(self, inputs, targets):\n        # Move alpha to the correct device (GPU/CPU) automatically\n        if self.alpha is not None and isinstance(self.alpha, torch.Tensor):\n            self.alpha = self.alpha.to(inputs.device)\n\n        # 1. Calculate Standard Cross Entropy (raw log_softmax)\n        # We assume inputs are raw logits (not probabilities)\n        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n        \n        # 2. Calculate probabilities (pt)\n        pt = torch.exp(-ce_loss)\n        \n        # 3. Calculate Alpha Factor\n        if self.alpha is not None:\n            if isinstance(self.alpha, torch.Tensor):\n                # Select the specific weight for the target class of each sample\n                alpha_t = self.alpha[targets]\n            else:\n                # Scalar alpha\n                alpha_t = self.alpha\n        else:\n            alpha_t = 1.0\n            \n        # 4. Focal Loss Formula\n        # Loss = -alpha * (1 - pt)^gamma * log(pt)\n        # Note: ce_loss is already -log(pt)\n        focal_loss = alpha_t * (1 - pt) ** self.gamma * ce_loss\n\n        # 5. Reduction\n        if self.reduction == 'mean':\n            return focal_loss.mean()\n        elif self.reduction == 'sum':\n            return focal_loss.sum()\n        else:\n            return focal_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:36:22.670751Z","iopub.execute_input":"2025-12-27T06:36:22.671038Z","iopub.status.idle":"2025-12-27T06:36:22.678024Z","shell.execute_reply.started":"2025-12-27T06:36:22.671018Z","shell.execute_reply":"2025-12-27T06:36:22.677239Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def train_fn(data_loader, model, optimizer, device, scheduler=None, start_steps=0, lambdaa = 1.2, retrain = False):\n    model.train()\n    total_loss = 0\n    # We use BCEWithLogitsLoss because our heads output raw logits (no sigmoid applied yet)\n    criterion = nn.BCEWithLogitsLoss()\n    \n    for idx, batch in enumerate(tqdm(data_loader, desc=\"Training\")):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        \n        # Labels are 0 (Hate), 1 (Offensive), 2 (Neither)\n        labels = batch['labels'].to(device)\n\n        optimizer.zero_grad()\n\n        # 1. Forward Pass\n        logitA, logitB = model(input_ids, attention_mask)\n\n        # 2. Create Binary Targets on the Fly\n        \n        # Target A: 1 if Toxic (Class 0 or 1), 0 if Neither (Class 2)\n        target_A = (labels <= 1).float()\n        \n        # Target B: 1 if Hate (Class 0), 0 if Offensive (Class 1)\n        target_B = (labels == 0).float()\n\n        # 3. Calculate Loss A (Toxic Detection)\n        # This is calculated for EVERY sample in the batch\n        loss_A = criterion(logitA, target_A)\n\n        # 4. Calculate Loss B (Hate Detection)\n        # This is calculated ONLY for samples that are actually Toxic (Label 0 or 1)\n        \n        # Create a mask: True where label is 0 or 1\n        toxic_mask = (labels <= 1)\n        \n        if toxic_mask.sum() > 0:\n            # Select only the logits and targets corresponding to toxic samples\n            loss_B = criterion(logitB[toxic_mask], target_B[toxic_mask])\n        else:\n            # If batch has no toxic samples, Loss B is 0\n            loss_B = torch.tensor(0.0, device=device)\n\n        # 5. Total Loss\n        # You can weigh these terms if needed (e.g., loss = loss_A + 2.0 * loss_B)\n        loss = loss_A + lambdaa * loss_B\n        \n        loss.backward()\n        \n        # Clip gradients to prevent explosion\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        \n        optimizer.step()\n        if scheduler:\n            scheduler.step()\n            \n        total_loss += loss.item()\n        current_step = start_steps + idx\n        if retrain: \n            writer.add_scalar('Loss/Train_New', loss.item(), current_step)\n        else:\n            writer.add_scalar('Loss/Train', loss.item(), current_step)\n    return total_loss / len(data_loader)\n\n# --- 3. Custom Evaluation Function (Hierarchical Inference) ---\ndef evaluate_fn(data_loader, model, device, threshold = 0.5):\n    model.eval()\n    \n    final_targets = []\n    final_predictions = []\n    \n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            # Get Logits\n            logitA, logitB = model(input_ids, attention_mask)\n            \n            # Convert to Probabilities\n            probA = torch.sigmoid(logitA) # Prob of being Toxic\n            probB = torch.sigmoid(logitB) # Prob of being Hate (conditional)\n            \n            # Hierarchical Decision Logic\n            batch_preds = []\n            for pA, pB in zip(probA, probB):\n                # Step 1: Is it Toxic?\n                if pA < 0.5:\n                    # Not Toxic -> Predict Class 2 (Neither)\n                    batch_preds.append(2)\n                else:\n                    # Is Toxic -> Step 2: Is it Hate?\n                    if pB > 0.5:\n                        # Hate -> Predict Class 0\n                        batch_preds.append(0)\n                    else:\n                        # Not Hate (but Toxic) -> Predict Class 1 (Offensive)\n                        batch_preds.append(1)\n            \n            final_targets.extend(labels.cpu().numpy())\n            final_predictions.extend(batch_preds)\n            \n    # Metrics\n    f1 = f1_score(final_targets, final_predictions, average='macro')\n    print(f\"\\nValidation F1: {f1:.4f}\")\n    \n    target_names = ['Hate Speech (0)', 'Offensive (1)', 'Neither (2)']\n    print(classification_report(final_targets, final_predictions, target_names=target_names))\n    \n    return f1\n\ndef train_fn_bert_cnn(data_loader, criterion, model, optimizer, device, scheduler=None, epoch_index = 0):\n    model.train()\n    total_loss = 0\n    losses = []\n    for idx, batch in enumerate(tqdm(data_loader, desc=\"Training\")):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        \n        # Labels are 0 (Hate), 1 (Offensive), 2 (Neither)\n        labels = batch['labels'].to(device)\n\n        optimizer.zero_grad()\n\n        # 1. Forward Pass\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        _, preds = torch.max(outputs, dim=1)\n        \n        # Focal Loss\n        loss = criterion(outputs, labels)\n\n        losses.append(loss.item())        \n        loss.backward()\n        \n        # Clip gradients to prevent explosion\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        \n        optimizer.step()\n        if scheduler:\n            scheduler.step()\n            \n        total_loss += loss.item()\n        current_step = epoch_index * len(data_loader) + idx\n        writer.add_scalar('Loss/Train_BERT_CNN', loss.item(), current_step)\n    return total_loss / len(data_loader)\n\ndef evaluate_fn_bert_cnn(data_loader, criterion, model, device, epoch_index = 0, is_testing = False):\n    model.eval()\n    \n    final_targets = []\n    final_predictions = []\n    val_losses = []\n    \n    with torch.no_grad():\n        for batch in tqdm(data_loader, desc=\"Evaluating\"):\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            # 1. Forward Pass\n            # The BertCNN model returns raw logits of shape [Batch, 3]\n            logits = model(input_ids, attention_mask)\n            \n            # 2. Calculate Loss (Validation Loss)\n            # We use the same Focal Loss criterion passed from the main loop\n            loss = criterion(logits, labels)\n            val_losses.append(loss.item())\n            \n            # 3. Get Predictions\n            # Since this is a standard Multi-class problem (0, 1, 2) for the CNN,\n            # we just take the argmax. \n            # (Note: The hierarchical logic was for the Two-Head model. \n            # For this BertCNN 3-class model, we use standard argmax).\n            _, preds = torch.max(logits, dim=1)\n            \n            final_targets.extend(labels.cpu().numpy())\n            final_predictions.extend(preds.cpu().numpy())\n            \n    # 4. Calculate Metrics\n    avg_val_loss = np.mean(val_losses)\n    val_f1 = f1_score(final_targets, final_predictions, average='macro')\n    if not is_testing: \n        writer.add_scalar('Loss/Validation_BERT_CNN', avg_val_loss, epoch_index)\n        writer.add_scalar('F1/Validation_BERT_CNN', val_f1, epoch_index)\n        print(f\"\\nValidation Loss: {avg_val_loss:.4f} | Validation F1: {val_f1:.4f}\")\n    \n    target_names = ['Hate Speech (0)', 'Offensive (1)', 'Neither (2)']\n    print(classification_report(final_targets, final_predictions, target_names=target_names))\n    \n    return avg_val_loss, val_f1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:36:24.655049Z","iopub.execute_input":"2025-12-27T06:36:24.655769Z","iopub.status.idle":"2025-12-27T06:36:24.674795Z","shell.execute_reply.started":"2025-12-27T06:36:24.655742Z","shell.execute_reply":"2025-12-27T06:36:24.673922Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model = BertTwoHeadHier(\"bert-base-uncased\").to(device)\n    \n# Initialize Optimizer\noptimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n\n# Assume train_loader and val_loader are already created from previous steps\ntotal_steps = len(train_loader) * EPOCHS\nscheduler = get_linear_schedule_with_warmup(optimizer, 0, total_steps)\nbest_val_loss = float('inf')\nsave_path = f\"BERT_{EPOCHS}_epochs_{LEARNING_RATE}_lr_BALANCED.pth\" if USE_BALANCED else f\"BERT_{EPOCHS}_epochs_{LEARNING_RATE}_lr.pth\"\ncurrent_steps = 0\n# Training Loop\nfor epoch in range(EPOCHS):\n    print(f\"Epoch {epoch + 1}/{EPOCHS}\")\n    train_loss = train_fn(train_loader, model, optimizer, device, scheduler, current_steps, lambdaa)\n    current_steps += len(train_loader)\n    model.eval()\n    val_loss = 0\n    val_criterion = nn.BCEWithLogitsLoss()\n    \n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['labels'].to(device)\n            \n            logitA, logitB = model(input_ids, attention_mask)\n            \n            target_A = (labels <= 1).float()\n            target_B = (labels == 0).float()\n            \n            loss_A = val_criterion(logitA, target_A)\n            toxic_mask = (labels <= 1)\n            if toxic_mask.sum() > 0:\n                loss_B = val_criterion(logitB[toxic_mask], target_B[toxic_mask])\n            else:\n                loss_B = torch.tensor(0.0, device=device)\n            \n            val_loss += (loss_A + lambdaa * loss_B).item()\n            \n    avg_val_loss = val_loss / len(val_loader)\n    \n    # Get Accuracy from your existing evaluate function\n    val_f1 = evaluate_fn(val_loader, model, device) # Assuming this returns accuracy\n    \n    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | Val F1: {val_f1:.4f}\")\n    \n    # --- 3. Logging to TensorBoard ---\n    writer.add_scalar('Loss/Validation', avg_val_loss, epoch)\n    writer.add_scalar('F1/Validation', val_f1, epoch)\n    \n    # --- 4. Save Model if Val Loss Improved ---\n    if avg_val_loss < best_val_loss:\n        print(f\"Validation loss decreased ({best_val_loss:.4f} --> {avg_val_loss:.4f}). Saving model...\")\n        torch.save(model.state_dict(), save_path)\n        print(f\"Saved at {save_path}\")\n        best_val_loss = avg_val_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:41:00.248960Z","iopub.execute_input":"2025-12-27T06:41:00.249694Z","iopub.status.idle":"2025-12-27T06:57:09.287269Z","shell.execute_reply.started":"2025-12-27T06:41:00.249667Z","shell.execute_reply":"2025-12-27T06:57:09.286473Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"292871d437ef4a2d832c2d78b18ac81a"}},"metadata":{}},{"name":"stdout","text":"Epoch 1/2\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 992/992 [07:07<00:00,  2.32it/s]\nEvaluating: 100%|██████████| 248/248 [00:27<00:00,  8.89it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation F1: 0.7675\n                 precision    recall  f1-score   support\n\nHate Speech (0)       0.54      0.42      0.47       220\n  Offensive (1)       0.94      0.96      0.95      3052\n    Neither (2)       0.88      0.88      0.88       694\n\n       accuracy                           0.91      3966\n      macro avg       0.79      0.75      0.77      3966\n   weighted avg       0.91      0.91      0.91      3966\n\nTrain Loss: 0.3897 | Val Loss: 0.3068 | Val F1: 0.7675\nValidation loss decreased (inf --> 0.3068). Saving model...\nSaved at BERT_2_epochs_1e-05_lr.pth\nEpoch 2/2\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 992/992 [07:07<00:00,  2.32it/s]\nEvaluating: 100%|██████████| 248/248 [00:27<00:00,  8.87it/s]","output_type":"stream"},{"name":"stdout","text":"\nValidation F1: 0.7235\n                 precision    recall  f1-score   support\n\nHate Speech (0)       0.60      0.23      0.33       220\n  Offensive (1)       0.93      0.97      0.95      3052\n    Neither (2)       0.90      0.89      0.89       694\n\n       accuracy                           0.92      3966\n      macro avg       0.81      0.70      0.72      3966\n   weighted avg       0.90      0.92      0.91      3966\n\nTrain Loss: 0.2870 | Val Loss: 0.3150 | Val F1: 0.7235\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def hierarchical_predict(probA, probB, threshold=0.4, toxic_cut=0.5):\n    probA = np.asarray(probA)\n    probB = np.asarray(probB)\n    pred = np.full_like(probA, 2, dtype=int)   # default Neither\n    toxic = probA >= toxic_cut\n    pred[toxic] = np.where(probB[toxic] > threshold, 0, 1)  # 0=hate, 1=offensive\n    return pred\n\n\n@torch.no_grad()\ndef mine_hard_hate_as_offensive_from_loader_new(\n    model,\n    loader,\n    device,\n    threshold=0.4,\n    toxic_cut=0.5,\n    top_k=None,          # None = keep all\n):\n    \"\"\"\n    Mine HARD POSITIVES:\n      - TRUE label = hate (0)\n      - PREDICTED as offensive (1)\n\n    These are false negatives for hate.\n    \"\"\"\n    model.eval().to(device)\n\n    rows = []\n\n    for batch in loader:\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n        texts = batch[\"text\"]\n\n        logitA, logitB = model(input_ids=input_ids, attention_mask=attention_mask)\n\n        pA = torch.sigmoid(logitA).cpu().numpy()\n        pB = torch.sigmoid(logitB).cpu().numpy()\n        y_true = labels.cpu().numpy()\n\n        preds = hierarchical_predict(pA, pB, threshold=threshold, toxic_cut=toxic_cut)\n\n        for t, y, a, b, p in zip(texts, y_true, pA, pB, preds):\n            # ✅ THIS is the key condition\n            if y == 0 and p == 1:\n                rows.append({\n                    \"clean_text\": t,\n                    \"class\": 0,\n                    \"probA_toxic\": float(a),\n                    \"probB_hate\": float(b),\n                    \"pred\": int(p),\n                    \"hard_score\": float(1.0 - b)  # lower pB = harder hate\n                })\n\n    df_hard = pd.DataFrame(rows)\n\n    if len(df_hard) == 0:\n        print(\"⚠️ No hate→offensive errors found (this is actually good).\")\n        return df_hard, {}\n\n    # Sort by hardest first (lowest hate confidence)\n    df_hard = df_hard.sort_values(\"hard_score\", ascending=False)\n\n    if top_k is not None:\n        df_hard = df_hard.head(top_k)\n\n    stats = {\n        \"hard_hate_count\": len(df_hard),\n        \"threshold\": threshold,\n        \"toxic_cut\": toxic_cut\n    }\n\n    return df_hard.reset_index(drop=True), stats","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:57:17.846308Z","iopub.execute_input":"2025-12-27T06:57:17.847113Z","iopub.status.idle":"2025-12-27T06:57:17.856172Z","shell.execute_reply.started":"2025-12-27T06:57:17.847073Z","shell.execute_reply":"2025-12-27T06:57:17.855322Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"hard_hate, stats = mine_hard_hate_as_offensive_from_loader_new(\n    model,\n    train_loader,\n    device,\n    threshold=0.4\n)\n\n\nprint(stats)\ndisplay(hard_hate.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T06:57:18.362529Z","iopub.execute_input":"2025-12-27T06:57:18.362878Z","iopub.status.idle":"2025-12-27T06:59:08.089989Z","shell.execute_reply.started":"2025-12-27T06:57:18.362848Z","shell.execute_reply":"2025-12-27T06:59:08.089065Z"}},"outputs":[{"name":"stdout","text":"{'hard_hate_count': 469, 'threshold': 0.4, 'toxic_cut': 0.5}\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"                                          clean_text  class  probA_toxic  \\\n0  :   true i need to sleep to make them gainz br...      0     0.996118   \n1  : : some of y'all hoes so worried about y'all ...      0     0.997510   \n2  : sometimes i wanna upper cut this bitch but i...      0     0.998408   \n3          \": stacey dash won   baddest bitch evaaaa      0     0.998677   \n4                        : tea bag a bitch. pahahaha      0     0.998706   \n\n   probB_hate  pred  hard_score  \n0    0.002242     1    0.997758  \n1    0.002871     1    0.997129  \n2    0.003196     1    0.996804  \n3    0.003372     1    0.996628  \n4    0.003508     1    0.996492  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>clean_text</th>\n      <th>class</th>\n      <th>probA_toxic</th>\n      <th>probB_hate</th>\n      <th>pred</th>\n      <th>hard_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>:   true i need to sleep to make them gainz br...</td>\n      <td>0</td>\n      <td>0.996118</td>\n      <td>0.002242</td>\n      <td>1</td>\n      <td>0.997758</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>: : some of y'all hoes so worried about y'all ...</td>\n      <td>0</td>\n      <td>0.997510</td>\n      <td>0.002871</td>\n      <td>1</td>\n      <td>0.997129</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>: sometimes i wanna upper cut this bitch but i...</td>\n      <td>0</td>\n      <td>0.998408</td>\n      <td>0.003196</td>\n      <td>1</td>\n      <td>0.996804</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\": stacey dash won   baddest bitch evaaaa</td>\n      <td>0</td>\n      <td>0.998677</td>\n      <td>0.003372</td>\n      <td>1</td>\n      <td>0.996628</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>: tea bag a bitch. pahahaha</td>\n      <td>0</td>\n      <td>0.998706</td>\n      <td>0.003508</td>\n      <td>1</td>\n      <td>0.996492</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"hard_hate.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T07:00:53.094866Z","iopub.execute_input":"2025-12-27T07:00:53.095512Z","iopub.status.idle":"2025-12-27T07:00:53.114733Z","shell.execute_reply.started":"2025-12-27T07:00:53.095481Z","shell.execute_reply":"2025-12-27T07:00:53.113916Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 469 entries, 0 to 468\nData columns (total 6 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   clean_text   469 non-null    object \n 1   class        469 non-null    int64  \n 2   probA_toxic  469 non-null    float64\n 3   probB_hate   469 non-null    float64\n 4   pred         469 non-null    int64  \n 5   hard_score   469 non-null    float64\ndtypes: float64(3), int64(2), object(1)\nmemory usage: 22.1+ KB\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def get_synonyms(word):\n    \"\"\"Get a list of synonyms for a given word.\"\"\"\n    synonyms = set()\n    for syn in wordnet.synsets(word):\n        for lemma in syn.lemmas():\n            synonym = lemma.name().replace(\"_\", \" \").lower()\n            if synonym != word:\n                synonyms.add(synonym)\n    return list(synonyms)\n\ndef augment_data(\n    text: str,\n    num_augmentations: int = 1,\n    min_replacements: int = 2,\n    max_attempts: int = 100,\n    seed: int | None = None,\n):\n    \"\"\"\n    Augment text by replacing at least `min_replacements` distinct words with synonyms.\n    Ensures augmented outputs differ from the original (or returns fewer if impossible).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    words = text.split()\n    if len(words) == 0:\n        return []\n\n    # Precompute which indices are replaceable and their synonym lists\n    replaceable = []\n    syn_cache = {}\n    for i, w in enumerate(words):\n        # basic cleanup to help wordnet (optional)\n        w_clean = re.sub(r\"[^A-Za-z']+\", \"\", w).lower()\n        if not w_clean:\n            continue\n        syns = get_synonyms(w_clean)\n        if syns:\n            replaceable.append(i)\n            syn_cache[i] = syns\n\n    # If we don't have enough replaceable words, can't guarantee min_replacements\n    if len(replaceable) < min_replacements:\n        # Return [] or fall back to fewer replacements (your choice)\n        return []\n\n    augmented_texts = []\n    original = \" \".join(words)\n\n    for _ in range(num_augmentations):\n        success = False\n\n        for _attempt in range(max_attempts):\n            new_words = words.copy()\n\n            # choose distinct indices to replace\n            idxs = rng.choice(replaceable, size=min_replacements, replace=False)\n\n            changed = 0\n            for idx in idxs:\n                syns = syn_cache[idx]\n                # pick synonym; if punctuation present, we keep original punctuation around it\n                chosen = rng.choice(syns)\n                new_words[idx] = chosen\n                changed += 1\n\n            augmented = \" \".join(new_words)\n\n            # ensure different from original AND we actually replaced enough\n            if augmented != original and changed >= min_replacements:\n                augmented_texts.append(augmented)\n                success = True\n                break\n\n        if not success:\n            # couldn't create a valid augmentation after max_attempts\n            # you can append original, skip, or return fewer; I skip.\n            pass\n\n    return augmented_texts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T07:00:58.217264Z","iopub.execute_input":"2025-12-27T07:00:58.217545Z","iopub.status.idle":"2025-12-27T07:00:58.226270Z","shell.execute_reply.started":"2025-12-27T07:00:58.217524Z","shell.execute_reply":"2025-12-27T07:00:58.225638Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"hard_negatives_df = hard_hate.loc[:, [\"clean_text\", \"class\"]]\naugmented_rows = []\n\nfor idx in range(len(hard_negatives_df)):\n    text = hard_negatives_df.loc[idx, \"clean_text\"]\n    label = hard_negatives_df.loc[idx, \"class\"]\n\n    augments = augment_data(\n        text,\n        num_augmentations=NUM_AUGMENTATIONS_PER_TEXT,\n        min_replacements=MIN_REPLACEMENT,\n        seed=idx\n    )\n\n    if augments:  # only augment iff non-empty\n        for aug_text in augments:\n            augmented_rows.append({\n                \"clean_text\": aug_text,\n                \"class\": label\n            })\n\n        # print(f\"[✓] Augmented: {text}\")\n        # print(augments)\n    else:\n        pass\n        # print(f\"[×] Skipped (no valid aug): {text}\")\n\naugmented_hard_negatives_df = pd.DataFrame(augmented_rows)\nprint(f\"Augmented {len(augmented_hard_negatives_df)} new texts of class 0\")\naugmented_hard_negatives_df.info()\nX_train_new = pd.concat([X_train, augmented_hard_negatives_df['clean_text']], axis = 0)\ny_train_new = pd.concat([y_train, augmented_hard_negatives_df['class']], axis = 0)\nprint(f\"New shape X train: {X_train_new.shape}\")\nprint(f\"New shape y train: {y_train_new.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T07:00:59.078132Z","iopub.execute_input":"2025-12-27T07:00:59.078410Z","iopub.status.idle":"2025-12-27T07:01:03.359294Z","shell.execute_reply.started":"2025-12-27T07:00:59.078388Z","shell.execute_reply":"2025-12-27T07:01:03.358660Z"}},"outputs":[{"name":"stdout","text":"Augmented 1608 new texts of class 0\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1608 entries, 0 to 1607\nData columns (total 2 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   clean_text  1608 non-null   object\n 1   class       1608 non-null   int64 \ndtypes: int64(1), object(1)\nmemory usage: 25.3+ KB\nNew shape X train: (17468,)\nNew shape y train: (17468,)\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"TARGET_OFFENSIVE = 5000   # or 7500\nSEED = 42\ntotal_df = pd.concat([X_train_new, y_train_new], axis = 1, keys=['clean_text', 'class'])\ndf_offensive = total_df[total_df[\"class\"] == 1]\ndf_offensive_down = (\n    df_offensive\n    .sample(n=TARGET_OFFENSIVE, random_state=SEED)\n    .reset_index(drop=True)\n)\ndf_hate = total_df[total_df[\"class\"] == 0]\ndf_neither = total_df[total_df[\"class\"] == 2]\n\ndf_train_balanced = pd.concat(\n    [\n        df_hate,\n        df_offensive_down,\n        df_neither\n    ],\n    ignore_index=True\n)\ndf_train_balanced.head()\ndf_train_balanced['class'].value_counts()\n\nX_train_new, y_train_new = df_train_balanced['clean_text'], df_train_balanced['class']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T07:01:07.451848Z","iopub.execute_input":"2025-12-27T07:01:07.452603Z","iopub.status.idle":"2025-12-27T07:01:07.466086Z","shell.execute_reply.started":"2025-12-27T07:01:07.452574Z","shell.execute_reply":"2025-12-27T07:01:07.465298Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"new_train_dataset = TwoHeadDataset(\n    texts=X_train_new, \n    labels=y_train_new, \n    tokenizer=tokenizer, \n    max_len=MAX_LEN\n)\n\nnew_train_loader = DataLoader(\n    new_train_dataset, \n    batch_size=BATCH_SIZE, \n    shuffle=True,\n    num_workers=2 # Optional: speeds up data loading\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T07:01:10.753324Z","iopub.execute_input":"2025-12-27T07:01:10.753641Z","iopub.status.idle":"2025-12-27T07:01:10.758803Z","shell.execute_reply.started":"2025-12-27T07:01:10.753597Z","shell.execute_reply":"2025-12-27T07:01:10.758036Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"new_model = BertCNN(n_classes=3)\nnew_model = new_model.to(device)\nclasses = np.unique(y_train)\nweights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train_new)\nprint(f\"Class weights: {weights}\")\n# Initialize Optimizer\nnew_optimizer = AdamW(new_model.parameters(), lr=RETRAIN_LEARNING_RATE)\ncriterion = FocalLoss(alpha=weights, gamma=1)\ntotal_steps = len(new_train_loader) * RETRAIN_EPOCHS\nnew_scheduler = get_linear_schedule_with_warmup(optimizer, 0, total_steps)\nbest_val_loss = float('inf')\nsave_path = f\"BERT_CNN_{RETRAIN_EPOCHS}_epochs_{RETRAIN_LEARNING_RATE}_lr_BALANCED.pth\" if USE_BALANCED else f\"BERT_CNN_{RETRAIN_EPOCHS}_epochs_{RETRAIN_LEARNING_RATE}_lr.pth\"\n\n# Training Loop\nfor epoch in range(RETRAIN_EPOCHS):\n    print(f\"Epoch {epoch + 1}/{RETRAIN_EPOCHS}\")\n    train_loss = train_fn_bert_cnn(new_train_loader, criterion, new_model, new_optimizer, device, new_scheduler, epoch)\n    val_loss, val_f1 = evaluate_fn_bert_cnn(val_loader, criterion, new_model, device, epoch)\n    print(f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val F1: {val_f1:.4f}\")\n    model.eval()\n    \n    \n    # --- 4. Save Model if Val Loss Improved ---\n    if val_loss < best_val_loss:\n        print(f\"Validation loss decreased ({best_val_loss:.4f} --> {val_loss:.4f}). Saving model...\")\n        torch.save(new_model.state_dict(), save_path)\n        print(f\"Saved at {save_path}\")\n        best_val_loss = val_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T07:34:22.605919Z","iopub.execute_input":"2025-12-27T07:34:22.606817Z","iopub.status.idle":"2025-12-27T07:54:56.348555Z","shell.execute_reply.started":"2025-12-27T07:34:22.606784Z","shell.execute_reply":"2025-12-27T07:54:56.347294Z"}},"outputs":[{"name":"stdout","text":"Class weights: [1.33859926 0.67786667 1.28578655]\nEpoch 1/4\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 636/636 [04:38<00:00,  2.28it/s]\nEvaluating: 100%|██████████| 248/248 [00:28<00:00,  8.71it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Loss: 0.2143 | Validation F1: 0.6891\n                 precision    recall  f1-score   support\n\nHate Speech (0)       0.22      0.63      0.33       220\n  Offensive (1)       0.98      0.81      0.88      3052\n    Neither (2)       0.79      0.93      0.86       694\n\n       accuracy                           0.82      3966\n      macro avg       0.66      0.79      0.69      3966\n   weighted avg       0.90      0.82      0.85      3966\n\nTrain Loss: 0.4126 | Val Loss: 0.2143 | Val F1: 0.6891\nValidation loss decreased (inf --> 0.2143). Saving model...\nSaved at BERT_CNN_4_epochs_5e-06_lr.pth\nEpoch 2/4\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 636/636 [04:39<00:00,  2.28it/s]\nEvaluating: 100%|██████████| 248/248 [00:28<00:00,  8.72it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Loss: 0.1739 | Validation F1: 0.7497\n                 precision    recall  f1-score   support\n\nHate Speech (0)       0.34      0.62      0.44       220\n  Offensive (1)       0.97      0.89      0.93      3052\n    Neither (2)       0.84      0.94      0.89       694\n\n       accuracy                           0.88      3966\n      macro avg       0.72      0.82      0.75      3966\n   weighted avg       0.91      0.88      0.89      3966\n\nTrain Loss: 0.2109 | Val Loss: 0.1739 | Val F1: 0.7497\nValidation loss decreased (0.2143 --> 0.1739). Saving model...\nSaved at BERT_CNN_4_epochs_5e-06_lr.pth\nEpoch 3/4\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 636/636 [04:39<00:00,  2.28it/s]\nEvaluating: 100%|██████████| 248/248 [00:28<00:00,  8.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nValidation Loss: 0.1717 | Validation F1: 0.7568\n                 precision    recall  f1-score   support\n\nHate Speech (0)       0.35      0.65      0.45       220\n  Offensive (1)       0.97      0.90      0.93      3052\n    Neither (2)       0.87      0.91      0.89       694\n\n       accuracy                           0.88      3966\n      macro avg       0.73      0.82      0.76      3966\n   weighted avg       0.91      0.88      0.90      3966\n\nTrain Loss: 0.1590 | Val Loss: 0.1717 | Val F1: 0.7568\nValidation loss decreased (0.1739 --> 0.1717). Saving model...\nSaved at BERT_CNN_4_epochs_5e-06_lr.pth\nEpoch 4/4\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 636/636 [04:39<00:00,  2.28it/s]\nEvaluating: 100%|██████████| 248/248 [00:28<00:00,  8.72it/s]","output_type":"stream"},{"name":"stdout","text":"\nValidation Loss: 0.1762 | Validation F1: 0.7616\n                 precision    recall  f1-score   support\n\nHate Speech (0)       0.40      0.52      0.45       220\n  Offensive (1)       0.95      0.93      0.94      3052\n    Neither (2)       0.88      0.90      0.89       694\n\n       accuracy                           0.90      3966\n      macro avg       0.75      0.78      0.76      3966\n   weighted avg       0.91      0.90      0.91      3966\n\nTrain Loss: 0.1303 | Val Loss: 0.1762 | Val F1: 0.7616\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"saved_model = BertCNN(n_classes=3).to(device)\nsaved_model.load_state_dict(torch.load(save_path, map_location=device))\ntest_loss, test_f1 = evaluate_fn_bert_cnn(test_loader, criterion, saved_model, device, epoch, is_testing = True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-27T07:57:27.456493Z","iopub.execute_input":"2025-12-27T07:57:27.457328Z","iopub.status.idle":"2025-12-27T07:58:03.280435Z","shell.execute_reply.started":"2025-12-27T07:57:27.457294Z","shell.execute_reply":"2025-12-27T07:58:03.279569Z"}},"outputs":[{"name":"stderr","text":"Evaluating: 100%|██████████| 310/310 [00:35<00:00,  8.83it/s]","output_type":"stream"},{"name":"stdout","text":"                 precision    recall  f1-score   support\n\nHate Speech (0)       0.36      0.65      0.46       286\n  Offensive (1)       0.97      0.90      0.93      3838\n    Neither (2)       0.87      0.91      0.89       833\n\n       accuracy                           0.89      4957\n      macro avg       0.73      0.82      0.76      4957\n   weighted avg       0.91      0.89      0.90      4957\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":21}]}